{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3626478a-d4e5-4271-9274-77bae6da197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Create a Doc object from the file owlcreek.txt\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ca4ad3-9a32-4d1d-a7c0-98f0a874a378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.How many tokens are contained in the file?\n",
    "tokens_num = len(doc)\n",
    "tokens_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4735a37e-a219-44fc-8751-74df1e87a5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.How many sentences are contained in the file?\n",
    "num_sentences = len(list(doc.sents))\n",
    "num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4573e29-af2b-439a-bbd6-35ae94fc3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.  \n"
     ]
    }
   ],
   "source": [
    "#4.Print the second sentence in the document\n",
    "sentences = list(doc.sents)\n",
    "sec_sentence = sentences[1].text\n",
    "print(sec_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bc3675d-f80c-4c73-9a27-de8f2854d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \t DET \t det \t the\n",
      "man \t NOUN \t poss \t man\n",
      "'s \t PART \t case \t 's\n",
      "hands \t NOUN \t nsubj \t hand\n",
      "were \t AUX \t ROOT \t be\n",
      "behind \t ADP \t prep \t behind\n",
      "\n",
      " \t SPACE \t dep \t \n",
      "\n",
      "his \t PRON \t poss \t his\n",
      "back \t NOUN \t pobj \t back\n",
      ", \t PUNCT \t punct \t ,\n",
      "the \t DET \t det \t the\n",
      "wrists \t NOUN \t appos \t wrist\n",
      "bound \t VERB \t acl \t bind\n",
      "with \t ADP \t prep \t with\n",
      "a \t DET \t det \t a\n",
      "cord \t NOUN \t pobj \t cord\n",
      ". \t PUNCT \t punct \t .\n",
      "  \t SPACE \t dep \t  \n"
     ]
    }
   ],
   "source": [
    "#5. For each token in the sentence above, print its text, POS tag, dep tag and lemma.\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in sec_sentence:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.dep_, '\\t', token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2d633e6-c456-4a7d-9dfc-1b33b29eec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12881893835109366681 Swimming 3 5 swimming vigorously\n",
      "12881893835109366681 Swimming 26 29 swimming...vigorously\n"
     ]
    }
   ],
   "source": [
    "#6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text.\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "pattern1 = [{'LOWER': 'swimming'}, {'LOWER': 'vigorously'}]  \n",
    "pattern2 = [{'LOWER': 'swimming'}, {'IS_PUNCT': True, 'OP': '*'}, {'LOWER': 'vigorously'}]\n",
    "\n",
    "\n",
    "matcher.add('Swimming', [pattern1, pattern2])\n",
    "\n",
    "\n",
    "doc = nlp(\"\"\"The athlete was swimming vigorously across the lake, determined to reach the other side. \n",
    "Even as the waves grew stronger, he kept swimming...vigorously, refusing to slow down.\"\"\")\n",
    "\n",
    "\n",
    "found_matches = matcher(doc) \n",
    "\n",
    "\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # Get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7dac60-05db-48dc-a620-69bf9112c03c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
