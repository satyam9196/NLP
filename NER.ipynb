{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3626478a-d4e5-4271-9274-77bae6da197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Create a Doc object from the file owlcreek.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996737b2-ac5d-476c-85ae-6921740cf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "with open(\"owlcreek.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87ca4ad3-9a32-4d1d-a7c0-98f0a874a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.How many tokens are contained in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1992dd96-e0e2-42b3-857b-7032b27ca269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_num = len(doc)\n",
    "tokens_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4735a37e-a219-44fc-8751-74df1e87a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.How many sentences are contained in the file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed506fe9-33b2-4a5d-ab54-05f4754473f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sentences = len(list(doc.sents))\n",
    "num_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d87c3-2bf8-45e6-8ea9-6dfdf98821f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.Print the second sentence in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4573e29-af2b-439a-bbd6-35ae94fc3ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man's hands were behind\n",
      "his back, the wrists bound with a cord.  \n"
     ]
    }
   ],
   "source": [
    "sentences = list(doc.sents)\n",
    "sec_sentence = sentences[1].text\n",
    "print(sec_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f701a3c-ce10-4f46-b30c-c9ccbd1f638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. For each token in the sentence above, print its text, POS tag, dep tag and lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c336d594-4176-4575-b814-d4be6675ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here \t ADV \t advmod \t here\n",
      "is \t AUX \t ROOT \t be\n",
      "another \t DET \t det \t another\n",
      "one \t NUM \t nsubj \t one\n",
      ". \t PUNCT \t punct \t .\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a sentence. Here is another one.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Let's assume you're referring to the second sentence\n",
    "sec_sentence = list(doc.sents)[1]  # extract the second sentence from the doc\n",
    "\n",
    "for token in sec_sentence:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.dep_, '\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74eeab7-9102-4f36-94f7-1c317ee59117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2d633e6-c456-4a7d-9dfc-1b33b29eec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12881893835109366681 Swimming 3 5 swimming vigorously\n",
      "12881893835109366681 Swimming 26 29 swimming...vigorously\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "pattern1 = [{'LOWER': 'swimming'}, {'LOWER': 'vigorously'}]  \n",
    "pattern2 = [{'LOWER': 'swimming'}, {'IS_PUNCT': True, 'OP': '*'}, {'LOWER': 'vigorously'}]\n",
    "\n",
    "\n",
    "matcher.add('Swimming', [pattern1, pattern2])\n",
    "\n",
    "\n",
    "doc = nlp(\"\"\"The athlete was swimming vigorously across the lake, determined to reach the other side. \n",
    "Even as the waves grew stronger, he kept swimming...vigorously, refusing to slow down.\"\"\")\n",
    "\n",
    "\n",
    "found_matches = matcher(doc) \n",
    "\n",
    "\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # Get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d4831-b2e0-49eb-896b-b222864112b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
