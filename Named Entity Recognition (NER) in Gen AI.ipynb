{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3604c281-d8f9-485a-91d5-5c736fd9eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92796b0-1d5c-4cb3-adc4-edf362e5cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weite a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "            \n",
    "        else:\n",
    "              print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ba9a7d-5360-483d-a51e-ea016cbfff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "Washington Monuments - GPE - Countries, cities, states\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"May I go to Washington, DC next May to see the Washington Monuments?\")\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60b5f67-e6e4-4a9e-80c8-e6de66f420c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 dollars 4 6 20 31 MONEY\n",
      "Microsoft 11 12 53 62 ORG\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.start, ent.end, ent.start_char,ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19fbd76-7af2-47be-a1d7-7b64345e0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "Can AUX aux\n",
      "I PRON nsubj\n",
      "please INTJ intj\n",
      "borrow VERB ROOT\n",
      "500 NUM nummod\n",
      "dollars NOUN dobj\n",
      "from ADP prep\n",
      "you PRON pobj\n",
      "to PART aux\n",
      "buy VERB advcl\n",
      "some DET det\n",
      "Microsoft PROPN compound\n",
      "stock NOUN dobj\n",
      "? PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens:\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "299522ae-9201-4386-91d7-348c2e0fb92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.K - ORG - Companies, agencies, institutions, etc.\n",
      "$6 million - MONEY - Monetary values, including unit\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Tesla to build a U.K factory for $6 million')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015978a2-0d4f-4fa8-8ead-e76cbd66e73f",
   "metadata": {},
   "source": [
    "## Right now, Spacy does not recognize \"Tesla\" as a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0b461c-d14f-4080-b685-7b232c21a84e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 0 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m new_ent \u001b[38;5;241m=\u001b[39m Span(doc,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39mORG)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#Add the entity to the existing Doc object\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m doc\u001b[38;5;241m.\u001b[39ments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(doc\u001b[38;5;241m.\u001b[39ments) \u001b[38;5;241m+\u001b[39m [new_ent]\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\New folder\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:798\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\New folder\\Lib\\site-packages\\spacy\\tokens\\doc.pyx:835\u001b[0m, in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 0 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "#Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG']\n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = Span(doc,0,1, label=ORG)\n",
    "\n",
    "#Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + [new_ent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a2699-8508-49bd-8b9b-18dc8904dcac",
   "metadata": {},
   "source": [
    "## In the code above, the arguments passed to Span() are:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "654152ff-4f8f-4545-b464-fd4d9b283ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "U.K - ORG - Companies, agencies, institutions, etc.\n",
      "$6 million - MONEY - Monetary values, including unit\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29cf39-6843-4be5-9eca-3b696658e778",
   "metadata": {},
   "source": [
    "# Adding a name Entity to All matching Spans\n",
    " what if we want to tag all accourance of \"Tesla\" ? In this section we show how to use the \n",
    " PhaseMatcher to identify a series of spans in the Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6dd636c-08c3-4f8b-8c06-1043e937e73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first - ORDINAL - \"first\", \"second\", etc.\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u' Our comapny plans to introduce a new vaccum cleaner.'\n",
    "          u'If successful, rthe vaccum cleaner will be our first product.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea330d55-e4c1-4cb5-845d-80b445a5c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import phraseMatcher and create a matcher object:\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db51a8e-757b-43e1-868a-a7d92e50a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the desired phrase patterns:\n",
    "phrase_list = ['vaccum cleaner' , 'vaccum-cleaner']\n",
    "phrase_patterns = [nlp(txt) for txt in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43ae3825-7876-4005-b647-4994db96392a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2689272359382549672, 8, 10), (2689272359382549672, 15, 17)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the patterns to our matcher object:\n",
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "\n",
    "# Apply the matcher to our Doc object:\n",
    "matches = matcher(doc)\n",
    "\n",
    "# See what matches occur:\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b797ec00-9d70-4777-9985-f6eae2e6d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create spans from each match, and create named entities from them:\n",
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc.vocab.strings[u'PRODUCT']\n",
    "\n",
    "new_ents = [Span(doc, match[1],match[2],label=PROD) for match in matches]\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1146306-b963-4b6f-9e94-90dc2411dc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaccum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "vaccum cleaner - PRODUCT - Objects, vehicles, foods, etc. (not services)\n",
      "first - ORDINAL - \"first\", \"second\", etc.\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ecf57-0157-44d4-902f-7db5b47890a5",
   "metadata": {},
   "source": [
    "# Counting Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72696e58-47a7-406c-9891-a59cc568696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7fe6a47-7cf7-4bc5-b361-0916c4a3500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label =='MONEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7307ffb7-6e53-4867-9d1c-0c074378d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 - MONEY - Monetary values, including unit\n",
      "five dollars - MONEY - Monetary values, including unit\n",
      "No named entities found.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally priced at $29.50,\\nthe sweater was marked down to five dollars.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b1a1fc-449e-4016-9047-3a5805a6a906",
   "metadata": {},
   "source": [
    "Noun Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59944f-e13a-425b-aa58-81c5391f5145",
   "metadata": {},
   "source": [
    "Noun Chunks components:\n",
    "\n",
    "'.text'           The original noun chunk text\n",
    "'.root.text'      The original text of the word connecting the noun chunk to the rest of the parse.\n",
    "'.root.dep_'      Dependency relation connecting the root to its head.\n",
    "'/rrot.head.text' The text of the root token's head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a25a3ff-d675-469d-a9f0-474176e24ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomus cars - cars _ nsubj _ shift\n",
      "insurance liability - liability _ dobj _ shift\n",
      "manufactures - manufactures _ pobj _ towards\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Autonomus cars shift insurance liability towards manufactures.\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text+' - '+chunk.root.text+' _ '+chunk.root.dep_+' _ '+chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1e177-04d7-4d50-b797-e13820fb8cfb",
   "metadata": {},
   "source": [
    "Doc.noun_chunks is a generator function:\n",
    "\n",
    "Previouslywe mentioned that doc objects do not retain a list of sentences, but they through the Doc.sents generator.\n",
    "it's the same with Doc.noun_chunks - lists can be created if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2032e1-3205-4928-9fb7-e40a34c33200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.noun_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a5bb3-4f0d-45ca-ae56-ebb1265fa1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
