{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee445c05-7f91-42ca-877c-80244db0d034",
   "metadata": {},
   "source": [
    "Vocabulary and Matching \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b1a627-1c3a-4501-83be-53eb519ef673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard reports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0a75ffe-4cca-49c7-92aa-2b224cd1fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f584efb-05f4-43d9-9cba-fcafdbf7f506",
   "metadata": {},
   "source": [
    "#Creating Patterns\n",
    "\n",
    "In literature,the phrase 'solar power' might appear as one word or two,with or withaut a hyphen. \n",
    "in this section we will develop a matcher named \"SolarPower\" that finds all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c28761aa-6d70-4cee-abbd-2522ded496e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT':True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec8022d-ebba-4322-b3c8-255e096738a4",
   "metadata": {},
   "source": [
    "Applying the matcher to a Doc object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0abfe8fa-5845-4243-a4f7-6583d5d7a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae963e62-a247-43d2-acc5-c3db6798878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de73c8-f499-4838-bd9c-cb10dfa14fd0",
   "metadata": {},
   "source": [
    "matcher returns a list of tupples.each tuple contains an ID for the match, with start & end tokens that map to the span doc[sytart:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9015d455-36ea-4c42-b51f-39a676324219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar power\n",
      "8656102463236116519 SolarPower 10 11 solarpower\n",
      "8656102463236116519 SolarPower 13 16 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]   # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74d6fdd-128d-4c4d-a01f-a7455f624de9",
   "metadata": {},
   "source": [
    "## Settings pattern options and qualifiers\n",
    "\n",
    "you can make the token rules optional an 'OP':'*' argument. This lets us stremline our pattern list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b4e2ace-25df-4fc0-804a-d6b3c902a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#redefine the patterns:\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT':True, 'OP':'*'}, {'LOWER': 'power'}]\n",
    "\n",
    "#Add the new set of patterns to the 'solarPowe' matcher:\n",
    "matcher.add('SolarPower',[pattern1, pattern2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25d8adc8-7e75-4b45-a881-0e535d4dfa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 10, 11), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac7c19d-5040-4117-84cc-a6a3e5313e0d",
   "metadata": {},
   "source": [
    "# Be careful with lemmas!\n",
    "\n",
    "if we wanted to match on both'solar poer' and 'solar powered', it might be tempeting to look for the lemma of 'powered; and expect it to be 'power'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fac24bf-6567-4959-b40f-6817191328ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT':True, 'OP':'*'}, {'LEMMA': 'power'}]     \n",
    "\n",
    "#Remove the old patterns to avoid duplication:\n",
    "matcher.remove('SolarPower')\n",
    "\n",
    "matcher.add('SolarPower',[pattern1, pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e897b5a6-c172-4e84-8ad8-b0a24de1df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Solar-powered energy runs solar-powered cars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "159c0a1e-6d7c-4f56-b062-0a0b7f1333d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 0, 3), (8656102463236116519, 5, 8)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3c52ba-dc80-43f3-981f-9f005928569c",
   "metadata": {},
   "source": [
    "# PhraseMatcher\n",
    "\n",
    "In the above section we used token patterns to perform rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0c61486-772c-402c-9a54-a9f6a6bf9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform standard imports, reset nlp\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5e24db2-0a17-4480-9840-f715044158d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PhaseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher (nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe31c9a4-6bf3-4e2f-8562-d53edb236d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reaganomics.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreaganomics.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     doc3 \u001b[38;5;241m=\u001b[39m nlp(f\u001b[38;5;241m.\u001b[39mread())\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\New folder\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reaganomics.txt'"
     ]
    }
   ],
   "source": [
    "with open('reaganomics.txt', 'r') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a860fefe-8609-46a6-b525-5bb90584c203",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m L1 \u001b[38;5;241m=\u001b[39m (doc3)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(L1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc3' is not defined"
     ]
    }
   ],
   "source": [
    "L1 = (doc3)\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f317d5a-8c06-4128-b2ab-def70e6c8bb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m matcher\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVoodooEconomics\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39mphrase_patterns)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#Build alist of matches:\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m matches \u001b[38;5;241m=\u001b[39m matcher(doc3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc3' is not defined"
     ]
    }
   ],
   "source": [
    "# First, create a list of match phrases\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics',\n",
    "                'free-market economics']     # ye 4 hme search krna h text file me\n",
    "\n",
    "# Next, convert each phrase to a Doc object:\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "# Pass each Doc object into matcher (note the use of the asterisk!):\n",
    "matcher.add('VoodooEconomics', None, *phrase_patterns)\n",
    "\n",
    "#Build alist of matches:\n",
    "matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f39308-83c2-4380-9bd8-1cb80e0f9bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# (match_id, start, end)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m matches\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "# (match_id, start, end)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "744ba01f-7a10-4acc-846f-3754cafdf07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Solar power industry continues to grow as demand for solarpower increases. Solar-power cars are gaining popularity."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291e68b-9205-4b06-9dd9-4fe2743c0e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
